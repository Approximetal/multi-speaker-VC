<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Cross-Lingual-VC</title>
<style type="text/css">
</style></head>
<body>
<h2><strong>Audio Samples from "Improving Model Stability and Training Efficiency in  Multi-speaker Voice Conversion with Data Redundancy Reduction</strong>"</h2>

<h3>Authors: </h3>
Zhiyuan Zhao, Jingjun Liang, Luoyu Bai, Linhuang Yan, Zehong Zheng, Zhiyong Yang, Wan Ding, Dongyan Huang
<h3>Abstract: </h3>
  <p>
The success of the neural network makes it prevalent in speech synthesis. However, there is some deficiency in neural-network-based multi-speaker VC tasks. Specifically, the limitations are the desire for data and computation and pronunciation errors. The current mainstream method of voice conversion is a combination of Automatic Speech Recognition and Text-to-Speech (ASR-TTS). Although it has provided outstanding quality and stability in recent speech synthesis competitions, this approach is susceptible to the performance of ASR, which requires far more data than speech synthesis for training. Considering the restrictions of ASR-TTS, we propose two methods to enhance the stability of our VC system. Firstly, we adopt data redundancy reduction in the training dataset to balance the distribution of vocabulary and avoid uncommon words being ignored during the training process. Our method significantly improves the stability of converted speech, which reduce the WER from 3.44% to 3.02%. Secondly, we construct a one-to-many training system, which takes parallel TTS synthesized speech and multi-speaker natural speech signals, to disentangle speaker characteristics from speech contents for pronunciation error reduction. The experiment result shows that the WER of our system is 2.59% lower than that of the ASR-TTS system.  </p>
<hr>
  <h5>&nbsp;</h5>
  

  
<h3>Performance of multi-speaker voice conversion system</h3>

<p>We conduct a Mean Option Score (MOS) test to evaluate the quality of synthesised speech, a male and a female are chosen from the internal dataset as target speakers. We calculate the average score of MOS with 95\% confidence intervals.</p>

<!--
<p>We pick up one sentence from <a href="https://openslr.org/38/">ST-CMDS</a> Dataset for example, meanwhile use TTS model to synthesize a same sentence. Then use these two audios as input for one-to-many and many-to-many models.</p>

<p>&nbsp;</p>
-->
<table border="1">
  <tr>
    <td><div width="600" align="center">Target Speaker</div></td>
    <td colspan="1"> <p align="center">Sample 1 (Male)</p> </td>
    <td colspan="1"> <p align="center">Sample 2 (Male)</p> </td>
    <td colspan="1"> <p align="center">Sample 3 (Female)</p> </td>
    <td colspan="1"> <p align="center">Sample 4 (Female)</p> </td>
  </tr>
  <tr>
    <td><div align="center">Ground Truth</div></td>
        <td><audio src="wavs/035247.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/035138.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005268.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005175.wav" controls="controls"> </audio></td>
  </tr>
    <tr>
    <td><div width="600" align="center">Parrotron + WaveGAN</div></td>
        <td><audio src="wavs/035247_vc2_PG.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/035138_vc2_PG.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005268_vc2_PG.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005175_vc2_PG.wav" controls="controls"> </audio></td>
  </tr>
      <tr>
    <td><div width="600" align="center">ASR-TTS + World</div></td>
        <td><audio src="wavs/035247_vc1.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/035138_vc1.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005268_vc1.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005175_vc1.wav" controls="controls"> </audio></td>
  </tr>
      <tr>
    <td><div width="600" align="center">Proposed + WaveGAN</div></td>
        <td><audio src="wavs/035247_vc2_FG.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/035138_vc2_FG.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005268_vc2_FG.wav" controls="controls"> </audio></td>
        <td><audio src="wavs/005175_vc2_FG.wav" controls="controls"> </audio></td>
  </tr>

</table>
<h3>&nbsp;</h3>
<h3>&nbsp;</h3>

</body></html>

